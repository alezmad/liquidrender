# ISS-129: Compiler Pipeline Underspecified - Complete Compiler Spec

**Issue Type:** Developer Experience
**Category:** Evidence
**Severity:** High
**Status:** Resolved

---

## Problem Statement

Section 17 (Compilation Pipeline) shows a high-level diagram but lacks:

1. **Detailed phase specifications** - What each phase does exactly
2. **Intermediate representations** - AST structure, IR formats
3. **Validation checkpoints** - What validates when
4. **Error propagation** - How errors bubble up
5. **Optimization passes** - Are there any? Where?

---

## Resolution

### 1. Complete Compilation Pipeline

Add to **§17.1 LiquidCode → LiquidSchema**:

```typescript
/**
 * ═══════════════════════════════════════════════════════════════
 * COMPLETE COMPILATION PIPELINE SPECIFICATION
 * ═══════════════════════════════════════════════════════════════
 */

// ─────────────────────────────────────────────────────────────────
// PHASE 1: TOKENIZATION
// ─────────────────────────────────────────────────────────────────

function tokenize(source: string): Token[] {
  // See §6.6.2 for complete algorithm
  // Output: Stream of tokens with positions
}

// ─────────────────────────────────────────────────────────────────
// PHASE 2: PARSING
// ─────────────────────────────────────────────────────────────────

interface AST {
  mode: 'generation' | 'mutation' | 'query';
  statements: ASTNode[];
  sourceMap: SourceMap;
}

interface ASTNode {
  type: string;
  location: SourceLocation;
  // Variant-specific fields
}

function parse(tokens: Token[]): AST {
  // See §6.6.3 for complete algorithm
  // Output: Abstract Syntax Tree
}

// ─────────────────────────────────────────────────────────────────
// PHASE 3: SEMANTIC ANALYSIS
// ─────────────────────────────────────────────────────────────────

interface SemanticContext {
  dataFingerprint?: DataFingerprint;
  slotContext?: SlotContext;
  existingSchema?: LiquidSchema;  // For mutations
}

interface AnalyzedAST extends AST {
  resolvedReferences: Map<string, string>;  // Selector → UID
  typeAnnotations: Map<string, BlockType>;
  bindingSuggestions: Map<string, BindingSuggestion[]>;
  signalGraph: SignalGraph;
}

function analyzeSemantics(ast: AST, context: SemanticContext): AnalyzedAST {
  const analyzed: AnalyzedAST = { ...ast, resolvedReferences: new Map(), ... };

  // 1. Resolve all selectors to UIDs
  for (const node of ast.statements) {
    if (node.type === 'mutation' || node.type === 'query') {
      const selector = node.selector;
      const uids = resolveSelector(selector, context.existingSchema);
      analyzed.resolvedReferences.set(selector, uids);
    }
  }

  // 2. Validate block types
  for (const node of ast.statements) {
    if (node.type === 'block') {
      if (!isValidBlockType(node.blockType)) {
        throw new SemanticError(`Unknown block type: ${node.blockType}`);
      }
    }
  }

  // 3. Generate binding suggestions
  if (context.dataFingerprint) {
    for (const node of ast.statements) {
      if (node.type === 'block' && !node.binding) {
        const suggestions = suggestBindings(node.blockType, context.dataFingerprint);
        analyzed.bindingSuggestions.set(node.id, suggestions);
      }
    }
  }

  // 4. Build signal graph
  analyzed.signalGraph = buildSignalGraph(ast);

  // 5. Validate signal consistency
  validateSignalGraph(analyzed.signalGraph);

  return analyzed;
}

// ─────────────────────────────────────────────────────────────────
// PHASE 4: SCHEMA GENERATION
// ─────────────────────────────────────────────────────────────────

function generateSchema(analyzedAST: AnalyzedAST, context: SemanticContext): LiquidSchema {
  const schema: LiquidSchema = {
    version: '2.0',
    scope: 'interface',
    uid: generateUID('s'),
    title: inferTitle(analyzedAST),
    generatedAt: new Date().toISOString(),
    layout: generateLayout(analyzedAST),
    blocks: generateBlocks(analyzedAST, context),
    signals: extractSignals(analyzedAST),
  };

  return schema;
}

function generateLayout(ast: AnalyzedAST): LayoutBlock {
  const layoutNode = ast.statements.find(s => s.type === 'layout');

  switch (layoutNode.layoutType) {
    case 'grid':
      return {
        type: 'grid',
        uid: generateUID('b'),
        config: {
          type: 'grid',
          columns: layoutNode.columns,
          rows: layoutNode.rows || 'auto',
        },
        children: [],
      };

    case 'stack':
      return {
        type: 'stack',
        uid: generateUID('b'),
        config: {
          type: 'stack',
          direction: layoutNode.direction || 'vertical',
        },
        children: [],
      };

    // ... other layout types
  }
}

function generateBlocks(ast: AnalyzedAST, context: SemanticContext): Block[] {
  const blocks: Block[] = [];

  for (const node of ast.statements) {
    if (node.type !== 'block') continue;

    const block: Block = {
      uid: generateUID('b'),
      type: node.blockType,
    };

    // Add explicit ID if provided
    if (node.explicitId) {
      block.id = node.explicitId;
    }

    // Add binding
    if (node.binding) {
      block.binding = expandBinding(node.binding, context.dataFingerprint);
    } else if (ast.bindingSuggestions.has(node.id)) {
      // Use high-confidence suggestion
      const suggestions = ast.bindingSuggestions.get(node.id);
      const highConfidence = suggestions.find(s => s.score > 0.8);
      if (highConfidence) {
        block.binding = highConfidence.binding;
      }
    }

    // Add signals
    if (node.signals.length > 0) {
      block.signals = {
        emits: node.signals.filter(s => s.direction === 'emit'),
        receives: node.signals.filter(s => s.direction === 'receive'),
      };
    }

    // Add layout hints
    if (node.layoutHints.length > 0) {
      block.layout = expandLayoutHints(node.layoutHints);
    }

    blocks.push(block);
  }

  return blocks;
}

// ─────────────────────────────────────────────────────────────────
// PHASE 5: VALIDATION
// ─────────────────────────────────────────────────────────────────

function validate(schema: LiquidSchema, strictMode: boolean): ValidationResult {
  try {
    // Zod validation
    const validated = LiquidSchemaSchema.parse(schema);

    // Additional semantic validation
    const warnings = [];

    // Check for unused signals
    const declaredSignals = new Set(Object.keys(schema.signals || {}));
    const usedSignals = new Set<string>();
    for (const block of schema.blocks) {
      block.signals?.emits?.forEach(e => usedSignals.add(e.signal));
      block.signals?.receives?.forEach(r => usedSignals.add(r.signal));
    }
    for (const signal of declaredSignals) {
      if (!usedSignals.has(signal)) {
        warnings.push({ type: 'unused-signal', message: `Signal '${signal}' is declared but not used` });
      }
    }

    // Check for orphaned receives
    for (const block of schema.blocks) {
      for (const receive of block.signals?.receives || []) {
        if (!declaredSignals.has(receive.signal)) {
          throw new ValidationError(`Block receives unknown signal '${receive.signal}'`);
        }
      }
    }

    return {
      valid: true,
      errors: [],
      warnings: strictMode ? warnings.map(w => ({ ...w, level: 'error' })) : warnings,
    };
  } catch (error) {
    return {
      valid: false,
      errors: formatZodErrors(error),
      warnings: [],
    };
  }
}

// ─────────────────────────────────────────────────────────────────
// PHASE 6: OPTIMIZATION (Optional)
// ─────────────────────────────────────────────────────────────────

function optimize(schema: LiquidSchema): LiquidSchema {
  let optimized = { ...schema };

  // Optimization 1: Deduplicate identical bindings
  optimized = deduplicateBindings(optimized);

  // Optimization 2: Inline single-use signals
  optimized = inlineSignals(optimized);

  // Optimization 3: Remove unreachable blocks (in slots)
  optimized = removeUnreachableBlocks(optimized);

  // Optimization 4: Canonicalize field order (for caching)
  optimized = canonicalizeFieldOrder(optimized);

  return optimized;
}

// ─────────────────────────────────────────────────────────────────
// COMPLETE COMPILER
// ─────────────────────────────────────────────────────────────────

export class LiquidCompiler {
  compile(
    source: string,
    context: CompilationContext
  ): CompilationResult {
    const startTime = performance.now();

    try {
      // Phase 1: Tokenize
      const tokens = tokenize(source);

      // Phase 2: Parse
      const ast = parse(tokens);

      // Phase 3: Semantic analysis
      const analyzedAST = analyzeSemantics(ast, context);

      // Phase 4: Generate schema
      let schema = generateSchema(analyzedAST, context);

      // Phase 5: Validate
      const validationResult = validate(schema, context.strictMode || false);
      if (!validationResult.valid) {
        return {
          success: false,
          errors: validationResult.errors,
          warnings: validationResult.warnings,
          metadata: {
            durationMs: performance.now() - startTime,
            tokenCount: tokens.length,
            blockCount: 0,
            validationPassed: false,
          },
        };
      }

      // Phase 6: Optimize (optional)
      if (context.optimize !== false) {
        schema = optimize(schema);
      }

      return {
        success: true,
        schema,
        errors: [],
        warnings: validationResult.warnings,
        metadata: {
          durationMs: performance.now() - startTime,
          tokenCount: tokens.length,
          blockCount: schema.blocks.length,
          validationPassed: true,
        },
      };
    } catch (error) {
      return {
        success: false,
        errors: [formatError(error)],
        warnings: [],
        metadata: {
          durationMs: performance.now() - startTime,
          tokenCount: 0,
          blockCount: 0,
          validationPassed: false,
        },
      };
    }
  }
}
```

### 2. Validation Checkpoints

Add to **§17.5 Validation Strategy**:

```markdown
## 17.5 Validation Strategy

Validation occurs at multiple checkpoints to fail fast:

```
CHECKPOINT 1: Tokenization
├─ Lexical errors (unknown characters)
├─ Unterminated strings
└─ Invalid number formats

CHECKPOINT 2: Parsing
├─ Syntax errors (unexpected tokens)
├─ Missing required tokens
└─ Unbalanced delimiters

CHECKPOINT 3: Semantic Analysis
├─ Unknown block types
├─ Invalid selectors
├─ Unresolved references
├─ Type mismatches
└─ Signal graph cycles

CHECKPOINT 4: Schema Validation
├─ Zod schema validation
├─ UID format validation
├─ Required field checks
└─ Field type checks

CHECKPOINT 5: Semantic Validation
├─ Unused signal warnings
├─ Orphaned signal receives
├─ Binding coherence
└─ Layout constraint violations
```

**Early Exit:** Compilation stops at first checkpoint failure.

**Error Accumulation:** Within a checkpoint, accumulate all errors before failing.
```

### 3. Error Propagation

Add to **§17.6 Error Propagation**:

```typescript
class CompilationError extends Error {
  constructor(
    message: string,
    public phase: CompilationPhase,
    public location?: SourceLocation,
    public suggestion?: string
  ) {
    super(message);
  }
}

type CompilationPhase =
  | 'tokenize'
  | 'parse'
  | 'semantic-analysis'
  | 'schema-generation'
  | 'validation'
  | 'optimization';

// Error context wrapping
function wrapError(error: Error, phase: CompilationPhase): CompilationError {
  if (error instanceof CompilationError) return error;

  return new CompilationError(
    error.message,
    phase,
    extractLocation(error),
    suggestFix(error, phase)
  );
}
```

---

## Testing Criteria

1. **Phase Isolation:**
   - [ ] Each phase can be tested independently
   - [ ] Intermediate representations validated

2. **Error Handling:**
   - [ ] All error types covered
   - [ ] Errors include source location
   - [ ] Suggestions provided

3. **Performance:**
   - [ ] Compilation meets budget (<50ms P99)
   - [ ] Large schemas (100+ blocks) compile

4. **Optimization:**
   - [ ] Optimizations preserve semantics
   - [ ] Optimized schemas validate

---

## Resolution Summary

Complete compiler specification with:
1. **6-phase pipeline** - Tokenize → Parse → Analyze → Generate → Validate → Optimize
2. **Intermediate representations** - AST, AnalyzedAST, LiquidSchema
3. **5 validation checkpoints** - Fail fast at each phase
4. **Error propagation** - Wrapped errors with phase context
5. **Optimization passes** - 4 semantic-preserving optimizations

Developers can now build compliant compilers.
