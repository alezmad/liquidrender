server.tool('relate', {
description: 'Discover relationships between sources',
parameters: {
sourceA: { type: 'string' },
sourceB: { type: 'string' }
},
handler: async ({ sourceA, sourceB }) => {
return await relationships.findPath(sourceA, sourceB);
}
});

// Tool: Create a binding dynamically
server.tool('bind', {
description: 'Create a data binding for visualization',
parameters: {
name: { type: 'string' },
source: { type: 'string' },
query: { type: 'object' } // groupBy, filter, aggregate, join
},
handler: async ({ name, source, query }) => {
const binding = await bindingFactory.create(name, source, query);
registry.registerBinding(binding);
return { binding: `:${name}`, ready: true };
}
});

// Tool: Preview data
server.tool('sample', {
description: 'Get sample rows from a source',
parameters: {
source: { type: 'string' },
limit: { type: 'number', default: 5 }
},
handler: async ({ source, limit }) => {
return await registry.sample(source, limit);
}
});

// Tool: Semantic search for columns
server.tool('search', {
description: 'Find columns matching a concept',
parameters: {
query: { type: 'string' } // e.g., "customer identifier"
},
handler: async ({ query }) => {
return await embeddings.search(query, 5);
}
});

server.start();

---

The Flow

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ARCHITECTURE â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ DATA SOURCES â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Postgres â”‚ â”‚ CSV â”‚ â”‚ XLSX â”‚ â”‚ REST API â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ CONNECTORS (existing) â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ BaseConnector â†’ getSchema() â†’ query() â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ CONTEXT ENGINE (new) â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Schema Cache â”‚ â”‚ Embeddings â”‚ â”‚ Relationship â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ (in-memory) â”‚ â”‚ (in-memory) â”‚ â”‚ Graph â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ (adj list) â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ DATA PROFILER â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Type inference â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Cardinality analysis â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Role classification (metric/dim/time/id) â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Sample extraction â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ MCP SERVER (new) â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Tools: discover | describe | relate | bind | sample â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ CLAUDE â”‚
â”‚ â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Uses MCP tools to explore data â†’ Generates LiquidCode â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ LIQUIDUI RENDERER (existing) â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Parses DSL â†’ Resolves bindings â†’ Renders React â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

When You DO Need Specialized Tech

| Scenario                  | Tech                 | Why                      |
| ------------------------- | -------------------- | ------------------------ |
| 10,000+ columns           | Vector DB (Pinecone) | Fast ANN search at scale |
| Complex multi-hop lineage | Graph DB (Neo4j)     | Efficient path queries   |
| Real-time streaming       | Kafka + Flink        | Event processing         |
| Sub-second at scale       | ClickHouse/DuckDB    | OLAP queries             |

For LiquidRender's use case (10-100 tables, interactive dashboards)?

- In-memory Map for schema cache âœ“
- Simple array with cosine similarity for embeddings âœ“
- Adjacency list for relationships âœ“
- SQLite or DuckDB if you need local persistence âœ“

---

The Revised Workflow Proposal

Given this vision, here's what we should build:

| Component         | Tech                | Purpose                        |
| ----------------- | ------------------- | ------------------------------ |
| ContextEngine     | TypeScript class    | Central coordinator            |
| SchemaCache       | Map<string, Schema> | In-memory schema storage       |
| Profiler          | Pure functions      | Analyze columns, infer roles   |
| EmbeddingStore    | Array<{id, vec}>    | Column semantic search         |
| RelationshipGraph | Map<string, Set>    | Adjacency list for joins       |
| MCPServer         | @anthropic/mcp-sdk  | Expose tools to Claude         |
| BindingFactory    | TypeScript class    | Generate bindings from queries |

Total: ~1,000 lines of TypeScript. No external databases.

---

My Unfiltered Take

The most powerful architecture is often the simplest one that works.

You have Claude â€” one of the most capable reasoning engines ever built. Use it. Let it explore, reason, and discover. Don't try to encode intelligence into a semantic layer. Let the LLM be the intelligence.

The MCP approach:

- âœ… Simpler implementation
- âœ… Always fresh metadata
- âœ… Transparent reasoning (you see the tool calls)
- âœ… Extensible (add new tools as needed)
- âœ… No infrastructure (no Pinecone, Neo4j, etc.)

---

Want me to revise the workflow with this MCP-centric architecture?

> what if we create an schema for the data that will be easy to use by the llm?\
> \
> maybe i am wrong, dont detour if not needed, what is your vision

âº Bash(.claude/hooks/play-tts.sh "You just said something important. Let me think
about this.")
â¿ ğŸµ Saved to: /Users/agutierrez/Desktop/liquidrender/.claude/audio/tts-padded-
1766711055.wav
ğŸ¤ Voice used: Alex (macOS Say)

âº ---
Yes. You're Right.

You just identified the core insight I was dancing around.

The Problem With My MCP Vision

I said "let the LLM explore via tools." But that means:

- Multiple round-trips (slow)
- Context switching (cognitive load on the LLM)
- No holistic view (sees one table at a time)

What if the LLM could see everything at once, in a format designed for its comprehension?

---

My Real Vision: LiquidData â€” A Data Description DSL

Just like LiquidCode is a compact DSL for describing UI:
Cn ^r [ Kp :revenue "Revenue" Ln :monthlyTrend "Trend" ]

LiquidData is a compact DSL for describing data context:

Â§ sales "Sales Database" @postgres

    â–¡ orders "Customer Orders"
      #id
      â†’customer : customers.id
      $amount "Order total" [49.99, 299.00, 1250.00]
      â—Šstatus [pending, shipped, delivered]
      âŒšcreated "Order date"

    â–¡ customers "Customer Accounts"
      #id
      @email
      ~name "Full name"
      â—Šsegment [free, pro, enterprise]
      $ltv "Lifetime value" [0, 847, 12500]

    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

    âˆ‘ revenue = sum(orders.amount)
    âˆ‘ aov = avg(orders.amount)
    âˆ‘ count = count(orders.id)

    âŠ time = orders.created [day|week|month|quarter|year]
    âŠ segment = customers.segment
    âŠ status = orders.status

    â‹ˆ orders.customer â†’ customers.id

Symbol Semantics

| Symbol | Meaning     | Why                     |
| ------ | ----------- | ----------------------- |
| Â§      | Data source | Database, file, API     |
| â–¡      | Table/sheet | Container of records    |
| #      | Identifier  | Primary key             |
| â†’      | Foreign key | Points to another table |
| $      | Metric      | Numeric, aggregatable   |
| â—Š      | Dimension   | Categorical, groupable  |
| âŒš     | Temporal    | Time-based field        |
| @      | Contact     | Email, phone, etc.      |
| ~      | Text        | Freeform string         |
| âˆ‘      | Aggregation | Pre-defined metric      |
| âŠ      | Grouping    | Dimension with levels   |
| â‹ˆ      | Join        | Relationship            |

---

Why This Is Powerful

1. Token Efficient

Full schema in ~200 tokens vs ~2000 for JSON Schema.

# JSON Schema: 847 tokens

{
"type": "object",
"properties": {
"orders": {
"type": "object",
"properties": {
"id": {"type": "integer", "description": "Primary key"},
"customer_id": {"type": "integer", "description": "Foreign key to customers"},
"amount": {"type": "number", "description": "Order total in USD"},
...
}
}
}
}

# LiquidData: 127 tokens

â–¡ orders "Customer Orders"
#id
â†’customer : customers.id
$amount "Order total" [49.99, 299.00]

2. Semantically Rich

The symbols encode meaning, not just structure:

- $amount â†’ LLM knows this is a metric (aggregate it)
- â—Šstatus â†’ LLM knows this is a dimension (group by it)
- âŒšcreated â†’ LLM knows this is temporal (time series possible)

3. Operations Are Obvious

â‹ˆ orders.customer â†’ customers.id

The LLM instantly knows: "I can join orders with customers on this key."

âŠ time = orders.created [day|week|month|quarter|year]

The LLM instantly knows: "I can group by time at these granularities."

4. Examples Are Inline

$amount "Order total" [49.99, 299.00, 1250.00]

Real values. The LLM understands the scale and distribution immediately.

---

But Wait â€” Is a New DSL Over-Engineering?

Let me be honest. Two options:

Option A: New DSL (LiquidData)

Â§ sales @postgres
â–¡ orders
$amount [49.99, 299.00]
âŒšcreated

Pros:

- Maximally compact
- Semantically encoded
- Consistent with LiquidCode philosophy

Cons:

- New syntax to learn
- Parser to build
- Potential for errors

Option B: Structured YAML (No New DSL)

source: sales
type: postgres

tables:
orders:
columns: - name: amount
role: metric
type: decimal
samples: [49.99, 299.00] - name: created
role: temporal
type: timestamp

metrics:
revenue: sum(orders.amount)

joins: - orders.customer_id â†’ customers.id

Pros:

- No new syntax
- Standard tooling
- Easy to generate

Cons:

- More verbose (~2x tokens)
- Less visually scannable

---

My Honest Take

Option B (YAML) is probably better for v1.

Why?

1. You can start immediately â€” no parser to build
2. LLMs already understand YAML â€” zero learning curve
3. Tooling exists â€” validation, generation, editing
4. You can evolve to DSL later â€” if token limits become a problem

The key insight isn't the format â€” it's the content:

# The magic is HERE, not in the syntax

role: metric # â† This tells the LLM "aggregate me"
role: dimension # â† This tells the LLM "group by me"
role: temporal # â† This tells the LLM "I'm time"
samples: [...] # â† This grounds the LLM in reality
joins: [...] # â† This enables multi-table queries

---

The Schema That Matters

# context.yaml â€” LLM-Native Data Context

version: 1
generated: 2024-12-26T10:00:00Z

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# SOURCES: Where data lives

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

sources: - id: sales-db
name: "Sales Database"
type: postgres

    - id: marketing-sheet
      name: "Marketing Campaigns"
      type: xlsx
      file: "campaigns-2024.xlsx"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ASSETS: Tables, sheets, endpoints

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

assets: - id: orders
source: sales-db
name: "Customer Orders"
rows: 125000
columns: - name: id
role: identifier
type: integer

        - name: customer_id
          role: foreign_key
          references: customers.id

        - name: amount
          role: metric
          type: decimal
          unit: currency
          stats: { min: 12.50, max: 9999.00, avg: 247.00 }
          samples: [49.99, 129.00, 499.00, 1250.00]

        - name: status
          role: dimension
          type: enum
          values: [pending, processing, shipped, delivered, cancelled]
          distribution: { delivered: 0.72, shipped: 0.15, pending: 0.08, cancelled: 0.05 }

        - name: created_at
          role: temporal
          type: timestamp
          range: [2023-01-01, 2024-12-26]
          granularities: [hour, day, week, month, quarter, year]

    - id: customers
      source: sales-db
      name: "Customer Accounts"
      rows: 45000
      columns:
        - name: id
          role: identifier

        - name: email
          role: contact
          type: email

        - name: segment
          role: dimension
          values: [free, starter, pro, enterprise]

        - name: lifetime_value
          role: metric
          unit: currency
          stats: { min: 0, max: 125000, avg: 847 }

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# VOCABULARY: What users might ask for

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

vocabulary:
metrics: - term: revenue
means: sum(orders.amount)
aliases: [sales, income, earnings]

      - term: order_count
        means: count(orders.id)
        aliases: [orders, transactions]

      - term: aov
        means: avg(orders.amount)
        aliases: [average order, basket size]

      - term: customers
        means: count(customers.id)
        aliases: [users, accounts]

      - term: ltv
        means: avg(customers.lifetime_value)
        aliases: [lifetime value, customer value]

    dimensions:
      - term: time
        means: orders.created_at
        aliases: [date, when, period]

      - term: status
        means: orders.status
        aliases: [order status, state]

      - term: segment
        means: customers.segment
        aliases: [tier, plan, customer type]

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# RELATIONSHIPS: How data connects

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

relationships: - from: orders.customer_id
to: customers.id
type: many-to-one
name: "order belongs to customer"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# PATTERNS: Common analytical queries

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

patterns: - name: "Revenue over time"
metrics: [revenue]
dimensions: [time]
visualization: Ln

    - name: "Revenue by segment"
      metrics: [revenue]
      dimensions: [segment]
      visualization: Br

    - name: "Order status breakdown"
      metrics: [order_count]
      dimensions: [status]
      visualization: Pi

    - name: "Customer detail"
      assets: [customers]
      visualization: Tb

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# OPERATIONS: What queries are possible

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

operations:
aggregatable: - orders.amount â†’ [sum, avg, min, max, count] - customers.lifetime_value â†’ [sum, avg, min, max]

    groupable:
      - orders.status
      - orders.created_at â†’ [hour, day, week, month, quarter, year]
      - customers.segment

    joinable:
      - [orders, customers] via orders.customer_id = customers.id

    filterable:
      - orders.status in [pending, shipped, delivered, cancelled]
      - orders.created_at between dates
      - orders.amount >= threshold
      - customers.segment in [free, starter, pro, enterprise]

---

How the LLM Uses This

User: "Show me revenue trends by customer segment"

LLM reads context.yaml and understands:

1. revenue â†’ sum(orders.amount) (from vocabulary)
2. segment â†’ customers.segment (from vocabulary)
3. trends â†’ temporal, needs time dimension
4. Requires join: orders â†’ customers (from relationships)

LLM generates:
Ln :revenueBySegment "Revenue Trends by Segment"

And creates the binding:
revenueBySegment: {
query: `       SELECT 
        DATE_TRUNC('month', o.created_at) as month,
        c.segment,
        SUM(o.amount) as revenue
      FROM orders o
      JOIN customers c ON o.customer_id = c.id
      GROUP BY 1, 2
      ORDER BY 1
    `,
type: 'array',
schema: { month: 'date', segment: 'string', revenue: 'number' }
}

---

The Pipeline

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DATA CONTEXT PIPELINE â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ DATA SOURCES â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚Postgresâ”‚ â”‚ XLSX â”‚ â”‚ API â”‚ â”‚
â”‚ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ CONTEXT GENERATOR â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ 1. INTROSPECT: Extract schemas from sources â”‚ â”‚
â”‚ â”‚ 2. PROFILE: Analyze each column (stats, samples) â”‚ â”‚
â”‚ â”‚ 3. CLASSIFY: Assign roles (metric/dimension/temporal) â”‚ â”‚
â”‚ â”‚ 4. RELATE: Discover joins via FK/name/value matching â”‚ â”‚
â”‚ â”‚ 5. VOCABULARY: Generate term â†’ field mappings â”‚ â”‚
â”‚ â”‚ 6. PATTERNS: Identify common query patterns â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ context.yaml â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ ~500-2000 tokens depending on data complexity â”‚ â”‚
â”‚ â”‚ Refreshed on: source change, manual trigger, schedule â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ SYSTEM PROMPT â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ [LiquidCode DSL Reference] â”‚ â”‚
â”‚ â”‚ [context.yaml content] â”‚ â”‚
â”‚ â”‚ [Examples] â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ CLAUDE â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ User: "Show me revenue by segment over time" â”‚ â”‚
â”‚ â”‚ Claude: Ln :revenueBySegment "Revenue by Segment" â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

My Final Vision

Don't build infrastructure. Build context.

The LLM doesn't need:

- âŒ Vector databases
- âŒ Graph databases
- âŒ MCP tools for exploration
- âŒ Complex semantic layers

The LLM needs:

- âœ… A well-structured context document (YAML)
- âœ… That captures semantics (roles, not just types)
- âœ… With examples (real values)
- âœ… And relationships (how to join)
- âœ… Generated automatically from data sources

That's it. One file. ~1000 tokens. Everything the LLM needs.

---

Should I design the workflow around generating this context.yaml?

> since the system has to be enterprise ready, to connect to databases, should we
> consider a pipeline from db schema, to liquidconnect schema, to a graph database
> or sth like that, or too much? i have no idea

âº Bash(.claude/hooks/play-tts.sh "Great question. Let me give you an honest enterprise
architecture assessment.")
â¿ ğŸµ Saved to: /Users/agutierrez/Desktop/liquidrender/.claude/audio/tts-padded-
1766711184.wav
ğŸ¤ Voice used: Alex (macOS Say)

âº ---
Honest Enterprise Assessment

Let me break this down pragmatically.

The Scale Question

| Scale      | Tables   | Relationships | What You Need        |
| ---------- | -------- | ------------- | -------------------- |
| Startup    | 5-20     | ~50           | In-memory objects    |
| SMB        | 20-100   | ~500          | JSON files or SQLite |
| Enterprise | 100-1000 | ~5000         | SQLite or Postgres   |
| Massive    | 1000+    | 50,000+       | Graph DB (Neo4j)     |

Reality check: Most companies have 50-200 tables across all their databases. That's ~1,000 relationships max. This fits comfortably in SQLite.

Graph databases solve problems you probably don't have yet.

---

What Enterprise Actually Needs

It's not fancy tech. It's boring reliability:

| Requirement    | What It Means                                | Solution                   |
| -------------- | -------------------------------------------- | -------------------------- |
| Multi-source   | Connect to Postgres, MySQL, Snowflake, files | Connectors (you have this) |
| Schema sync    | Detect when tables change                    | Incremental introspection  |
| Access control | Who can see what data                        | Permission layer           |
| Audit trail    | Who queried what when                        | Logging                    |
| Caching        | Don't re-introspect constantly               | TTL-based cache            |
| Reliability    | Don't crash on bad data                      | Error handling             |

None of this requires a graph database.

---

My Recommended Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LIQUIDCONTEXT ARCHITECTURE â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ DATA SOURCES â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚Postgresâ”‚ â”‚ MySQL â”‚ â”‚ XLSX â”‚ â”‚ CSV â”‚ â”‚ API â”‚ â”‚
â”‚ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ INTROSPECTION LAYER â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Schema â”‚ â”‚ Column â”‚ â”‚Relationship â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Extractor â”‚ â”‚ Profiler â”‚ â”‚ Discoverer â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â€¢ Extract tables, columns, types from each source â”‚ â”‚
â”‚ â”‚ â€¢ Profile columns: cardinality, nulls, samples, distribution â”‚ â”‚
â”‚ â”‚ â€¢ Discover relationships: FK â†’ explicit, name/value â†’ inferred â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ CONTEXT STORE (The "IR") â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ TypeScript interfaces stored in SQLite (or JSON for simple cases) â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ sources â”‚ id, type, connection, last_sync, status â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ assets â”‚ id, source_id, name, type, row_count, hash â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ columns â”‚ id, asset_id, name, type, role, stats, samplesâ”‚ â”‚ â”‚
â”‚ â”‚ â”‚ relations â”‚ from_col, to_col, type, confidence â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ vocabulary â”‚ term, definition, aliases â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ This is your "graph" â€” just relational tables with FKs â”‚ â”‚
â”‚ â”‚ SQLite can do all the traversal you need â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ CONTEXT GENERATOR â”‚
â”‚ â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ Query the store â†’ Generate context.yaml for LLM consumption â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ Options: â”‚ â”‚
â”‚ â”‚ â€¢ Full context (all sources, all tables) â”‚ â”‚
â”‚ â”‚ â€¢ Scoped context (specific sources or tables) â”‚ â”‚
â”‚ â”‚ â€¢ Minimal context (just vocabulary + relationships) â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ â–¼ â”‚
â”‚ OUTPUT â”‚
â”‚ â•â•â•â•â•â• â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ context.yaml â”‚ â†’ Embedded in LLM system prompt â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

The Intermediate Representation (IR)

This is the key. A clean set of TypeScript types that represent your data universe:

// context-store.ts â€” The Intermediate Representation

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// CORE ENTITIES
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface DataSource {
id: string;
name: string;
type: 'postgres' | 'mysql' | 'sqlite' | 'xlsx' | 'csv' | 'api';
connection: string; // Connection string or file path
status: 'connected' | 'disconnected' | 'error';
lastSync: Date;
syncInterval?: number; // ms, for auto-refresh
}

interface DataAsset {
id: string;
sourceId: string;
name: string; // Table name, sheet name, endpoint
path: string; // Full path: "postgres:sales/public/orders"
type: 'table' | 'view' | 'sheet' | 'endpoint';
rowCount: number;
schemaHash: string; // For change detection
lastProfiled: Date;
}

interface DataColumn {
id: string;
assetId: string;
name: string;

    // Type info
    dataType: string;       // Raw type from source (varchar, int8, etc.)
    nullable: boolean;

    // Semantic classification
    role: 'identifier' | 'metric' | 'dimension' | 'temporal' |
          'foreign_key' | 'text' | 'contact' | 'unknown';

    // For foreign keys
    references?: {
      assetId: string;
      columnId: string;
    };

    // Statistics (for metrics and dimensions)
    stats?: {
      distinct: number;     // Cardinality
      nullRate: number;     // 0.0 - 1.0
      min?: number;
      max?: number;
      mean?: number;
      distribution?: Record<string, number>;  // For enums
    };

    // Sample values (for LLM grounding)
    samples: unknown[];

    // For dimensions: possible values
    values?: string[];

    // For temporal: granularities available
    granularities?: ('hour' | 'day' | 'week' | 'month' | 'quarter' | 'year')[];

}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// RELATIONSHIPS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface Relationship {
id: string;
fromColumn: string; // Column ID
toColumn: string; // Column ID
type: 'one-to-one' | 'one-to-many' | 'many-to-many';

    // How was this discovered?
    source: 'foreign_key' | 'inferred_name' | 'inferred_value' | 'manual';
    confidence: number;     // 0.0 - 1.0

}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// SEMANTIC LAYER
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface Metric {
id: string;
name: string; // "revenue"
definition: string; // "sum(orders.amount)"
aliases: string[]; // ["sales", "income"]
unit?: 'currency' | 'percentage' | 'count' | 'duration';
format?: string; // "$0,0.00"

    // What column(s) is this derived from?
    sourceColumns: string[];
    aggregation: 'sum' | 'avg' | 'count' | 'min' | 'max' | 'custom';

}

interface Dimension {
id: string;
name: string; // "time"
sourceColumn: string; // Column ID
aliases: string[]; // ["date", "when"]

    // For hierarchical dimensions
    hierarchy?: string[];   // ["year", "quarter", "month", "day"]

    // For temporal dimensions
    granularities?: string[];

}

interface VocabularyTerm {
term: string;
type: 'metric' | 'dimension' | 'entity' | 'action';
resolves_to: string; // Metric ID, Dimension ID, or expression
aliases: string[];
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// PATTERNS
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface QueryPattern {
id: string;
name: string; // "Revenue over time"
description: string;
metrics: string[]; // Metric IDs
dimensions: string[]; // Dimension IDs
filters?: string[]; // Common filter patterns
visualization: 'Kp' | 'Ln' | 'Br' | 'Pi' | 'Tb' | 'Ls';
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// THE COMPLETE CONTEXT
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface LiquidContext {
version: string;
generatedAt: Date;

    sources: DataSource[];
    assets: DataAsset[];
    columns: DataColumn[];
    relationships: Relationship[];

    metrics: Metric[];
    dimensions: Dimension[];
    vocabulary: VocabularyTerm[];
    patterns: QueryPattern[];

}

---

Storage Options (Ranked by Complexity)

Level 1: JSON Files (Start Here)

.liquid-context/
â”œâ”€â”€ sources.json
â”œâ”€â”€ assets.json
â”œâ”€â”€ columns.json
â”œâ”€â”€ relationships.json
â”œâ”€â”€ vocabulary.json
â””â”€â”€ context.yaml # Generated for LLM

Pros: Dead simple, version controllable, no dependencies
Cons: No queries, full reload on change
When: 1-10 sources, <100 tables

Level 2: SQLite (When You Need Queries)

// Single file: .liquid-context/context.db

// Queries become possible:
SELECT c.\* FROM columns c
JOIN assets a ON c.asset_id = a.id
WHERE a.source_id = 'sales-db'
AND c.role = 'metric';

// Find join path (recursive CTE):
WITH RECURSIVE path AS (
SELECT from_column, to_column, 1 as depth
FROM relationships
WHERE from_column = 'orders.customer_id'
UNION ALL
SELECT r.from_column, r.to_column, p.depth + 1
FROM relationships r
JOIN path p ON r.from_column = p.to_column
WHERE p.depth < 5
)
SELECT \* FROM path WHERE to_column LIKE 'products.%';

Pros: Queryable, single file, no server
Cons: Slightly more complex
When: 10-50 sources, 100-500 tables

Level 3: PostgreSQL (When You Need Scale)

Same schema as SQLite, but in your existing Postgres.

Pros: Scales infinitely, can join with your actual data
Cons: Requires a database server
When: 50+ sources, 500+ tables, multi-user

Level 4: Graph DB (When You Hit Limits)

Only if you need:

- Complex multi-hop lineage queries
- Real-time impact analysis
- Graph algorithms (PageRank for importance, etc.)

When: 1000+ tables, complex lineage requirements

---

My Honest Recommendation

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ â”‚
â”‚ FOR V1: JSON Files + In-Memory Objects â”‚
â”‚ â”‚
â”‚ â€¢ Store IR as JSON files â”‚
â”‚ â€¢ Load into memory on startup â”‚
â”‚ â€¢ Build simple relationship index (Map<string, string[]>) â”‚
â”‚ â€¢ Generate context.yaml on demand â”‚
â”‚ â”‚
â”‚ This handles 90% of real-world use cases. â”‚
â”‚ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ FOR V2 (if needed): SQLite â”‚
â”‚ â”‚
â”‚ â€¢ When you need queryable metadata â”‚
â”‚ â€¢ When you have >100 tables â”‚
â”‚ â€¢ When you need incremental sync â”‚
â”‚ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â”‚
â”‚ FOR V3 (probably never): Graph DB â”‚
â”‚ â”‚
â”‚ â€¢ When you have enterprise data governance requirements â”‚
â”‚ â€¢ When you need sub-second complex lineage queries â”‚
â”‚ â€¢ When you have 1000+ tables â”‚
â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

---

The Pipeline (What We Actually Build)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONNECT â”‚â”€â”€â”€â”€â–¶â”‚ INTROSPECT â”‚â”€â”€â”€â”€â–¶â”‚ STORE â”‚â”€â”€â”€â”€â–¶â”‚ GENERATE â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ Connectors â”‚ â”‚ Extractors â”‚ â”‚ JSON/SQLite â”‚ â”‚ context.yaml â”‚
â”‚ (existing) â”‚ â”‚ Profilers â”‚ â”‚ (new) â”‚ â”‚ (new) â”‚
â”‚ â”‚ â”‚ Classifiers â”‚ â”‚ â”‚ â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â–¼ â–¼ â–¼ â–¼
BaseConnector SchemaExtractor ContextStore ContextGenerator
PostgresConn ColumnProfiler (IR types) (YAML output)
FileConnector RoleClassifier RelationshipIndex
RelationDiscoverer

---

Summary

| Question                      | Answer                                        |
| ----------------------------- | --------------------------------------------- |
| Do you need a graph database? | No. Not for v1, probably not for v2.          |
| Do you need a formal IR?      | Yes. TypeScript types â†’ JSON/SQLite storage.  |
| Do you need a pipeline?       | Yes. Connect â†’ Introspect â†’ Store â†’ Generate. |
| What's the output?            | context.yaml â€” A single file the LLM reads.   |

---

Should I design the workflow around this pipeline?

> ok, the liquid engine will be connected to enterprise who wants the power of liquid ui to
> understand their data... it is not about the data of this project

âº Now I understand the full picture. LiquidRender is an enterprise product - companies deploy it to connect their own databases, files, and APIs, then their users ask natural language questions to generate visualizations.

Revised Architecture: LiquidConnect

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ENTERPRISE DEPLOYMENT â”‚
â”‚ â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ LiquidConnect Platform â”‚ â”‚
â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Source â”‚ â”‚ Introspect â”‚ â”‚ Context â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Registry â”‚â”€â”€â–¶â”‚ Pipeline â”‚â”€â”€â–¶â”‚ Store â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Postgres â”‚ â”‚ â€¢ Schema â”‚ â”‚ â€¢ Assets â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ MySQL â”‚ â”‚ â€¢ Profile â”‚ â”‚ â€¢ Columns â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ XLSX/CSV â”‚ â”‚ â€¢ Classify â”‚ â”‚ â€¢ Relations â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ REST APIs â”‚ â”‚ â€¢ Relate â”‚ â”‚ â€¢ Semantics â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â–¼ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ Context Generator â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Produces LLM-Ready Context: â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Data Manifest (what exists) â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Semantic Layer (what it means) â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Relationship Graph (how it connects) â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â€¢ Query Patterns (common operations) â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â–¼ â”‚ â”‚
â”‚ â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚ â”‚ â”‚ LiquidRender Engine â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ User: "Show me revenue by region for Q4" â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â–¼ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ LLM + Context â†’ DSL: Br :q4_revenue_by_region "Q4 Revenue" â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â”‚ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ â–¼ â”‚ â”‚ â”‚
â”‚ â”‚ â”‚ Binding Resolver â†’ Query Enterprise DB â†’ Render Chart â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚
â”‚ ENTERPRISE DATA: â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Postgres â”‚ â”‚ MySQL â”‚ â”‚ XLSX â”‚ â”‚ APIs â”‚ â”‚
â”‚ â”‚ orders â”‚ â”‚ customersâ”‚ â”‚ budgets â”‚ â”‚ CRM â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The Core Innovation: Automatic Context Generation

When an enterprise connects a data source, LiquidConnect automatically:

1. Introspects the schema (tables, columns, types)
2. Profiles the data (samples, distributions, cardinality)
3. Classifies column roles (metric, dimension, temporal, identifier)
4. Discovers relationships (foreign keys, inferred joins)
5. Generates LLM-ready context

Let me create the TypeScript foundation for this:

âº Write(packages/liquid-render/src/platform/context/types.ts)
â¿ Wrote 385 lines to packages/liquid-render/src/platform/context/types.ts  
 // LiquidConnect Context Types
// ============================================================================
// Core type definitions for the enterprise data context system
// ============================================================================
/\*\*
_ Supported data source types
_/
export type SourceType =
| 'postgres'
â€¦ +375 lines (ctrl+o to expand)

âº Write(packages/liquid-render/src/platform/context/introspector.ts)
â¿ Wrote 484 lines to packages/liquid-render/src/platform/context/introspector.ts
// LiquidConnect Introspector
// ============================================================================
// Automatic schema introspection and column profiling
// ============================================================================
import type {
DataSource,
DataAsset,
DataColumn,
Relationship,
â€¦ +474 lines (ctrl+o to expand)

> for the context store, i want an agentic context orchestration with conditional
> loading for big contexts spread on different files or schemas...\
> \
> so context is always optimal for the user intent\
> \
> maybe there is a better way to do this, what is your vision?

âº That's a critical insight. Loading a full enterprise context (hundreds of tables, thousands of columns) would:

1. Blow up token costs
2. Dilute the LLM's focus
3. Add latency

Vision: Agentic Context Orchestration

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ USER QUERY â”‚
â”‚ "Show me revenue by region for Q4" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CONTEXT ORCHESTRATOR (Agent 0) â”‚
â”‚ â”‚
â”‚ Step 1: Parse Intent â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ intent: "aggregate visualization" â”‚ â”‚
â”‚ â”‚ entities: ["revenue", "region", "Q4"] â”‚ â”‚
â”‚ â”‚ operation: "group by dimension, filter by time" â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ Step 2: Search Context Index (always loaded, tiny) â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ index.yaml (~2KB): â”‚ â”‚
â”‚ â”‚ domains: â”‚ â”‚
â”‚ â”‚ - sales: [orders, revenue, products, regions] â”‚ â”‚
â”‚ â”‚ - customers: [users, segments, contacts] â”‚ â”‚
â”‚ â”‚ - inventory: [stock, warehouses, shipments] â”‚ â”‚
â”‚ â”‚ vocabulary: â”‚ â”‚
â”‚ â”‚ revenue: sales.orders.amount â”‚ â”‚
â”‚ â”‚ region: sales.regions â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ Step 3: Load Relevant Context Slices â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Load: context/sales/orders.yaml (contains revenue metric) â”‚ â”‚
â”‚ â”‚ Load: context/sales/regions.yaml (contains region dimension) â”‚ â”‚
â”‚ â”‚ Skip: context/customers/_ (not relevant) â”‚ â”‚
â”‚ â”‚ Skip: context/inventory/_ (not relevant) â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚ â”‚ â”‚
â”‚ Step 4: Compose Optimal Context â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Final context: ~500 tokens (instead of 50,000) â”‚ â”‚
â”‚ â”‚ - orders table schema â”‚ â”‚
â”‚ â”‚ - regions dimension with values â”‚ â”‚
â”‚ â”‚ - revenue metric definition â”‚ â”‚
â”‚ â”‚ - relevant relationships â”‚ â”‚
â”‚ â”‚ - time filtering patterns â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RENDER AGENT (Agent 1) â”‚
â”‚ â”‚
â”‚ Receives: Focused context + User query â”‚
â”‚ Outputs: DSL: Br :q4_revenue_by_region "Q4 Revenue by Region" â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

The Three-Layer Context Architecture

âº Write(packages/liquid-render/src/platform/context/orchestrator.ts)
â¿ Wrote 579 lines to packages/liquid-render/src/platform/context/orchestrator.ts
// Context Orchestrator
// ============================================================================
// Agentic context loading with intent-based selection
// ============================================================================
import type {
LiquidContext,
LLMContext,
DataAsset,
DataColumn,
â€¦ +569 lines (ctrl+o to expand)
â¿ Interrupted Â· What should Claude do instead?
